{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import nest_asyncio\n",
    "# import logging\n",
    "# import pandas as pd\n",
    "# from collections import deque\n",
    "# from datetime import datetime\n",
    "# import pyotp\n",
    "# import polars as pl\n",
    "# import numba_indicators \n",
    "# from  datetime import timedelta\n",
    "# from NorenRestApiPy.NorenApi import NorenApi\n",
    "\n",
    "# # Basic logger setup\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "#     handlers=[logging.StreamHandler()]\n",
    "# )\n",
    "# logger = logging.getLogger()\n",
    "\n",
    "# # Global variables\n",
    "# api = None\n",
    "# feed_opened = False\n",
    "# ring_buffers = {}  # Dictionary to hold ring buffers for each token\n",
    "# resampled_buffers = {}\n",
    "# RING_BUFFER_SIZE = 1000  # Example ring buffer size\n",
    "# RING_BUFFER_RESAMPLE_SIZE = 1000\n",
    "# resampling_enabled = {}  # Dictionary to track resampling status for each token and timeframe\n",
    "# VALID_TIMEFRAMES = ['1min', '5min']  # Add or remove timeframes as needed\n",
    "# last_tick_time = {}  # New: Track the last tick time for each token\n",
    "# active_subscriptions = set()  # Set to track active subscriptions\n",
    "\n",
    "# # Initialize API function\n",
    "# def initialize_api(credentials_file=\"usercred.xlsx\"):\n",
    "#     global api\n",
    "#     api = NorenApi(\n",
    "#         host=\"https://api.shoonya.com/NorenWClientTP/\",\n",
    "#         websocket=\"wss://api.shoonya.com/NorenWSTP/\"\n",
    "#     )\n",
    "\n",
    "#     credentials = pd.read_excel(credentials_file)\n",
    "#     user = credentials.iloc[0, 0]\n",
    "#     password = credentials.iloc[0, 1]\n",
    "#     vendor_code = credentials.iloc[0, 2]\n",
    "#     app_key = credentials.iloc[0, 3]\n",
    "#     imei = credentials.iloc[0, 4]\n",
    "#     qr_code = credentials.iloc[0, 5]\n",
    "#     factor2 = pyotp.TOTP(qr_code).now()\n",
    "\n",
    "#     # Perform login\n",
    "#     api.login_result = api.login(\n",
    "#         userid=user,\n",
    "#         password=password,\n",
    "#         twoFA=factor2,\n",
    "#         vendor_code=vendor_code,\n",
    "#         api_secret=app_key,\n",
    "#         imei=imei\n",
    "#     )\n",
    "\n",
    "# # Function to create ring buffers for each token\n",
    "# def create_ring_buffers(tokens):\n",
    "#     global ring_buffers\n",
    "#     for token in tokens:\n",
    "#         if token not in ring_buffers:\n",
    "#             ring_buffers[token] = deque(maxlen=RING_BUFFER_SIZE)\n",
    "#             last_tick_time[token] = None\n",
    "#             logger.info(f\"Created ring buffer for token: {token}\")\n",
    "\n",
    "# def create_resampled_buffers(tokens, timeframes):\n",
    "#     global resampled_buffers, resampling_enabled\n",
    "#     for token in tokens:\n",
    "#         if token not in resampled_buffers:\n",
    "#             resampled_buffers[token] = {}\n",
    "#             resampling_enabled[token] = {}\n",
    "#             logger.info(f\"Created resampled buffers entry for token: {token}\")\n",
    "        \n",
    "#         for timeframe in timeframes:\n",
    "#             if timeframe not in resampled_buffers[token]:\n",
    "#                 resampled_buffers[token][timeframe] = deque(maxlen=RING_BUFFER_RESAMPLE_SIZE)\n",
    "#                 resampling_enabled[token][timeframe] = False  # Default to disabled\n",
    "#                 logger.info(f\"Created resampled buffer for token {token} and timeframe: {timeframe}\")\n",
    "\n",
    "# # Function to enable/disable resampling\n",
    "# async def set_resampling(token, timeframe, enable):\n",
    "#     global resampling_enabled\n",
    "#     if token in resampling_enabled and timeframe in resampling_enabled[token]:\n",
    "#         resampling_enabled[token][timeframe] = enable\n",
    "#         logger.info(f\"Resampling {'enabled' if enable else 'disabled'} for token {token} and timeframe {timeframe}\")\n",
    "#     else:\n",
    "#         logger.warning(f\"Token {token} or timeframe {timeframe} not found in resampling_enabled\")\n",
    "\n",
    "# # Function to resample ticks\n",
    "# async def resample_ticks():\n",
    "#     global resampled_buffers, ring_buffers\n",
    "\n",
    "#     while True:\n",
    "#         await asyncio.sleep(1)  # Check every second\n",
    "\n",
    "#         for token, buffer in ring_buffers.items():\n",
    "#             if not buffer:\n",
    "#                 continue\n",
    "\n",
    "#             df = pd.DataFrame(list(buffer))\n",
    "#             df['tt'] = pd.to_datetime(df['tt'])\n",
    "#             df.set_index('tt', inplace=True)\n",
    "\n",
    "#             resampled = df['ltp'].resample('1min').ohlc()\n",
    "\n",
    "#             if token not in resampled_buffers:\n",
    "#                 resampled_buffers[token] = {}\n",
    "            \n",
    "#             resampled_buffers[token]['1min'] = deque(\n",
    "#                 resampled.reset_index().to_dict('records'),\n",
    "#                 maxlen=RING_BUFFER_RESAMPLE_SIZE\n",
    "#             )\n",
    "\n",
    "# # Event handler for feed updates (tick data)\n",
    "# def event_handler_feed_update(tick_data):\n",
    "#     try:\n",
    "#         if 'lp' in tick_data and 'tk' in tick_data:\n",
    "#             timest = datetime.fromtimestamp(int(tick_data['ft'])).isoformat()\n",
    "#             token = tick_data['tk']\n",
    "\n",
    "#             if token in ring_buffers:\n",
    "#                 # Append tick data to the respective token's ring buffer\n",
    "#                 ring_buffers[token].append({'ltp': float(tick_data['lp']), 'tt': timest})\n",
    "#                 last_tick_time[token] = datetime.fromisoformat(timest)\n",
    "                \n",
    "#             else:\n",
    "#                 logger.warning(f\"Token {token} not found in ring buffers. Ignoring tick.\")\n",
    "#     except (KeyError, ValueError) as e:\n",
    "#         logger.error(f\"Error processing tick data: {e}\")\n",
    "\n",
    "# # WebSocket connection and subscription handler\n",
    "# async def connect_and_subscribe():\n",
    "#     global feed_opened\n",
    "#     retry_delay = 1  # Initial retry delay in seconds\n",
    "#     max_retry_delay = 32  # Maximum retry delay in seconds\n",
    "#     max_retries = 10  # Maximum number of retries\n",
    "#     retries = 0  # Counter for retries\n",
    "\n",
    "#     while retries < max_retries:\n",
    "#         try:\n",
    "#             api.start_websocket(\n",
    "#                 order_update_callback=event_handler_order_update,\n",
    "#                 subscribe_callback=event_handler_feed_update,\n",
    "#                 socket_open_callback=open_callback,\n",
    "#                 socket_close_callback=close_callback\n",
    "#             )\n",
    "#             await wait_for_feed_open(timeout=30)  # Wait for feed to open with a timeout\n",
    "#             logger.info(\"WebSocket connected successfully.\")\n",
    "            \n",
    "#             # Initial subscription management (adjust as needed)\n",
    "#             await manage_subscriptions('add', 'MCX|432294')\n",
    "#             await manage_subscriptions('add', 'NSE|26009')\n",
    "#             await manage_subscriptions('add', 'NSE|26000')\n",
    "            \n",
    "#             retry_delay = 1  # Reset retry delay after successful connection\n",
    "#             retries = 0  # Reset retry counter\n",
    "#             await monitor_connection()\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"WebSocket connection error: {e}\")\n",
    "#             retries += 1\n",
    "#             logger.info(f\"Reconnecting in {retry_delay} seconds... (Attempt {retries}/{max_retries})\")\n",
    "#             await asyncio.sleep(retry_delay)\n",
    "#             retry_delay = min(retry_delay * 2, max_retry_delay)  # Exponential backoff\n",
    "\n",
    "#     if retries >= max_retries:\n",
    "#         logger.error(\"Max retries reached. Exiting.\")\n",
    "#         raise Exception(\"Max retries reached\")\n",
    "\n",
    "# # Manage subscriptions\n",
    "# async def manage_subscriptions(command, subscription):\n",
    "#     global active_subscriptions\n",
    "#     token = subscription.split('|')[1]  # Extract token from subscription string\n",
    "\n",
    "#     if command == 'add':\n",
    "#         if subscription not in active_subscriptions:\n",
    "#             api.subscribe([subscription])  # Subscribe to the new token\n",
    "#             active_subscriptions.add(subscription)\n",
    "#             create_ring_buffers([token])  # Create ring buffer for new token\n",
    "#             create_resampled_buffers([token], VALID_TIMEFRAMES)  # Create resampled buffers for new token\n",
    "#             logger.info(f\"Subscribed to {subscription}\")\n",
    "#             # Once the subscription is done and ring buffers are created, enable resampling\n",
    "#             for timeframe in VALID_TIMEFRAMES:\n",
    "#                 await set_resampling(token, timeframe, True)  # Enable resampling dynamically\n",
    "            \n",
    "#             logger.info(f\"Resampling enabled for token {token} for all valid timeframes.\")\n",
    "#         else:\n",
    "#             logger.warning(f\"Already subscribed to {subscription}\")\n",
    "\n",
    "#     elif command == 'remove':\n",
    "#         if subscription in active_subscriptions:\n",
    "#             api.unsubscribe([subscription])  # Unsubscribe from the token\n",
    "#             active_subscriptions.remove(subscription)\n",
    "#             # Note: We're not removing buffers here to preserve data. \n",
    "#             # You may want to add cleanup logic if needed.\n",
    "#             logger.info(f\"Unsubscribed from {subscription}\")\n",
    "#         else:\n",
    "#             logger.warning(f\"Not subscribed to {subscription}\")\n",
    "\n",
    "# # Wait for WebSocket feed to open\n",
    "# async def wait_for_feed_open(timeout):\n",
    "#     global feed_opened\n",
    "#     start_time = asyncio.get_event_loop().time()\n",
    "#     while not feed_opened:\n",
    "#         if asyncio.get_event_loop().time() - start_time > timeout:\n",
    "#             raise TimeoutError(\"Timed out waiting for feed to open\")\n",
    "#         await asyncio.sleep(1)\n",
    "\n",
    "# # Monitor the WebSocket connection\n",
    "# async def monitor_connection():\n",
    "#     global feed_opened\n",
    "#     while True:\n",
    "#         if not feed_opened:\n",
    "#             logger.warning(\"Feed closed unexpectedly. Reconnecting...\")\n",
    "#             raise Exception(\"Feed closed\")\n",
    "#         await asyncio.sleep(5)  # Check connection status every 5 seconds\n",
    "\n",
    "# # WebSocket close callback\n",
    "# def close_callback():\n",
    "#     global feed_opened\n",
    "#     feed_opened = False\n",
    "#     logger.warning(\"WebSocket connection closed.\")\n",
    "#     logger.info(\"Attempting to reconnect...\")\n",
    "\n",
    "# # WebSocket open callback\n",
    "# def open_callback():\n",
    "#     global feed_opened\n",
    "#     if not feed_opened:\n",
    "#         feed_opened = True\n",
    "#         logger.info('Feed Opened')\n",
    "#     else:\n",
    "#         logger.warning('Feed Opened callback called multiple times.')\n",
    "\n",
    "# # Event handler for order updates\n",
    "# def event_handler_order_update(data):\n",
    "#     logger.info(f\"Order update: {data}\")\n",
    "\n",
    "# async def main():\n",
    "#     initialize_api()  # Initialize the API\n",
    "#     await asyncio.gather(\n",
    "#         connect_and_subscribe(),  # This can run continuously\n",
    "#         resample_ticks()           # This will resample ticks concurrently\n",
    "#     )\n",
    "\n",
    "# # Event loop setup\n",
    "# loop = asyncio.get_event_loop()\n",
    "# loop.set_debug(True)\n",
    "# if loop.is_running():\n",
    "#     nest_asyncio.apply()\n",
    "# asyncio.create_task(main())\n",
    "# if not loop.is_running():\n",
    "#     try:\n",
    "#         loop.run_forever()\n",
    "#     except KeyboardInterrupt:\n",
    "#         logger.info(\"Received exit signal. Cleaning up...\")\n",
    "#     finally:\n",
    "#         loop.close()\n",
    "#         logger.info(\"Event loop closed. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await manage_subscriptions('add', 'NSE|26000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampling_enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await set_resampling('432294', '5min', False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from collections import deque\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pyotp\n",
    "from NorenRestApiPy.NorenApi import NorenApi\n",
    "\n",
    "class TickCollector:\n",
    "    def __init__(self, credentials_file=\"usercred.xlsx\"):\n",
    "        self.processing_lock = asyncio.Lock()\n",
    "        self.api = None\n",
    "        self.feed_opened = False\n",
    "        self.ring_buffers = {}\n",
    "        self.resampled_buffers = {}\n",
    "        self.resampling_enabled = {}\n",
    "        self.last_tick_time = {}\n",
    "        self.active_subscriptions = set()\n",
    "        self.RING_BUFFER_SIZE = 1000\n",
    "        self.RING_BUFFER_RESAMPLE_SIZE = 1000\n",
    "        self.VALID_TIMEFRAMES = ['1min', '5min']\n",
    "        \n",
    "        self.logger = self._setup_logger()\n",
    "        self._initialize_api(credentials_file)\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        return logger\n",
    "\n",
    "    def _initialize_api(self, credentials_file):\n",
    "        self.api = NorenApi(\n",
    "            host=\"https://api.shoonya.com/NorenWClientTP/\",\n",
    "            websocket=\"wss://api.shoonya.com/NorenWSTP/\"\n",
    "        )\n",
    "        credentials = pd.read_excel(credentials_file)\n",
    "        user = credentials.iloc[0, 0]\n",
    "        password = credentials.iloc[0, 1]\n",
    "        vendor_code = credentials.iloc[0, 2]\n",
    "        app_key = credentials.iloc[0, 3]\n",
    "        imei = credentials.iloc[0, 4]\n",
    "        qr_code = credentials.iloc[0, 5]\n",
    "        factor2 = pyotp.TOTP(qr_code).now()\n",
    "\n",
    "        self.api.login_result = self.api.login(\n",
    "            userid=user,\n",
    "            password=password,\n",
    "            twoFA=factor2,\n",
    "            vendor_code=vendor_code,\n",
    "            api_secret=app_key,\n",
    "            imei=imei\n",
    "        )\n",
    "\n",
    "    def create_ring_buffers(self, tokens):\n",
    "        for token in tokens:\n",
    "            if token not in self.ring_buffers:\n",
    "                self.ring_buffers[token] = deque(maxlen=self.RING_BUFFER_SIZE)\n",
    "                self.last_tick_time[token] = None\n",
    "                self.logger.info(f\"Created ring buffer for token: {token}\")\n",
    "\n",
    "    def create_resampled_buffers(self, tokens, timeframes):\n",
    "        for token in tokens:\n",
    "            if token not in self.resampled_buffers:\n",
    "                self.resampled_buffers[token] = {}\n",
    "                self.resampling_enabled[token] = {}\n",
    "                self.logger.info(f\"Created resampled buffers entry for token: {token}\")\n",
    "            \n",
    "            for timeframe in timeframes:\n",
    "                if timeframe not in self.resampled_buffers[token]:\n",
    "                    self.resampled_buffers[token][timeframe] = deque(maxlen=self.RING_BUFFER_RESAMPLE_SIZE)\n",
    "                    self.resampling_enabled[token][timeframe] = False\n",
    "                    self.logger.info(f\"Created resampled buffer for token {token} and timeframe: {timeframe}\")\n",
    "\n",
    "    async def set_resampling(self, token, timeframe, enable):\n",
    "        if token in self.resampling_enabled and timeframe in self.resampling_enabled[token]:\n",
    "            self.resampling_enabled[token][timeframe] = enable\n",
    "            self.logger.info(f\"Resampling {'enabled' if enable else 'disabled'} for token {token} and timeframe {timeframe}\")\n",
    "        else:\n",
    "            self.logger.warning(f\"Token {token} or timeframe {timeframe} not found in resampling_enabled\")\n",
    "\n",
    "\n",
    "    def event_handler_feed_update(self, tick_data):\n",
    "        try:\n",
    "            if 'lp' in tick_data and 'tk' in tick_data:\n",
    "                timest = datetime.fromtimestamp(int(tick_data['ft'])).isoformat()\n",
    "                token = tick_data['tk']\n",
    "                if token in self.ring_buffers:\n",
    "                    new_tick = {'tt': timest, 'ltp': float(tick_data['lp'])}\n",
    "                    self.ring_buffers[token].append(new_tick)\n",
    "                    self.last_tick_time[token] = datetime.fromisoformat(timest)\n",
    "                    #self.logger.info(f\"Added tick to buffer for token {token}. Ring_Buffer: {self.ring_buffers[token]}\")\n",
    "                else:\n",
    "                    self.logger.warning(f\"Token {token} not found in ring buffers. Ignoring tick.\")\n",
    "        except (KeyError, ValueError) as e:\n",
    "            self.logger.error(f\"Error processing tick data: {e}\")\n",
    "\n",
    " \n",
    "    async def connect_and_subscribe(self):\n",
    "        retry_delay = 1\n",
    "        max_retry_delay = 32\n",
    "        max_retries = 10\n",
    "        retries = 0\n",
    "\n",
    "        while retries < max_retries:\n",
    "            try:\n",
    "                self.api.start_websocket(\n",
    "                    order_update_callback=self.event_handler_order_update,\n",
    "                    subscribe_callback=self.event_handler_feed_update,\n",
    "                    socket_open_callback=self.open_callback,\n",
    "                    socket_close_callback=self.close_callback\n",
    "                )\n",
    "                await self.wait_for_feed_open(timeout=30)\n",
    "                self.logger.info(\"WebSocket connected successfully.\")\n",
    "                \n",
    "                await self.manage_subscriptions('add', 'MCX|432294')\n",
    "                #await self.manage_subscriptions('add', 'NSE|26009')\n",
    "                # await self.manage_subscriptions('add', 'NSE|26000')\n",
    "                \n",
    "                retry_delay = 1\n",
    "                retries = 0\n",
    "                await self.monitor_connection()\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"WebSocket connection error: {e}\")\n",
    "                retries += 1\n",
    "                self.logger.info(f\"Reconnecting in {retry_delay} seconds... (Attempt {retries}/{max_retries})\")\n",
    "                await asyncio.sleep(retry_delay)\n",
    "                retry_delay = min(retry_delay * 2, max_retry_delay)\n",
    "\n",
    "        if retries >= max_retries:\n",
    "            self.logger.error(\"Max retries reached. Exiting.\")\n",
    "            raise Exception(\"Max retries reached\")\n",
    "\n",
    "    async def manage_subscriptions(self, command, subscription):\n",
    "        token = subscription.split('|')[1]\n",
    "\n",
    "        if command == 'add':\n",
    "            if subscription not in self.active_subscriptions:\n",
    "                self.api.subscribe([subscription])\n",
    "                self.active_subscriptions.add(subscription)\n",
    "                self.create_ring_buffers([token])\n",
    "                self.create_resampled_buffers([token], self.VALID_TIMEFRAMES)\n",
    "                self.logger.info(f\"Subscribed to {subscription}\")\n",
    "                for timeframe in self.VALID_TIMEFRAMES:\n",
    "                    await self.set_resampling(token, timeframe, True)\n",
    "                self.logger.info(f\"Resampling enabled for token {token} for all valid timeframes.\")\n",
    "            else:\n",
    "                self.logger.warning(f\"Already subscribed to {subscription}\")\n",
    "        elif command == 'remove':\n",
    "            if subscription in self.active_subscriptions:\n",
    "                self.api.unsubscribe([subscription])\n",
    "                self.active_subscriptions.remove(subscription)\n",
    "                self.logger.info(f\"Unsubscribed from {subscription}\")\n",
    "            else:\n",
    "                self.logger.warning(f\"Not subscribed to {subscription}\")\n",
    "\n",
    "    async def wait_for_feed_open(self, timeout):\n",
    "        start_time = asyncio.get_event_loop().time()\n",
    "        while not self.feed_opened:\n",
    "            if asyncio.get_event_loop().time() - start_time > timeout:\n",
    "                raise TimeoutError(\"Timed out waiting for feed to open\")\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "    async def monitor_connection(self):\n",
    "        while True:\n",
    "            if not self.feed_opened:\n",
    "                self.logger.warning(\"Feed closed unexpectedly. Reconnecting...\")\n",
    "                raise Exception(\"Feed closed\")\n",
    "            await asyncio.sleep(5)\n",
    "\n",
    "    def close_callback(self):\n",
    "        self.feed_opened = False\n",
    "        self.logger.warning(\"WebSocket connection closed.\")\n",
    "        self.logger.info(\"Attempting to reconnect...\")\n",
    "\n",
    "    def open_callback(self):\n",
    "        if not self.feed_opened:\n",
    "            self.feed_opened = True\n",
    "            self.logger.info('Feed Opened')\n",
    "        else:\n",
    "            self.logger.warning('Feed Opened callback called multiple times.')\n",
    "\n",
    "    def event_handler_order_update(self, data):\n",
    "        self.logger.info(f\"Order update: {data}\")\n",
    "\n",
    "    async def run(self):\n",
    "        await asyncio.gather(\n",
    "            self.connect_and_subscribe()            \n",
    "        )\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, tick_collector):\n",
    "        self.tick_collector = tick_collector\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.last_processed_time = {}\n",
    "        self.IDLE_THRESHOLD = timedelta(minutes=1)  # Adjust this as needed\n",
    "\n",
    "    # async def ohlc_resampling(self):\n",
    "    #     async with self.tick_collector.processing_lock:\n",
    "    #         for token, ticks in self.tick_collector.ring_buffers.items():\n",
    "    #             if not ticks:\n",
    "    #                 self.logger.info(f\"No ticks available for {token}\")\n",
    "    #                 continue\n",
    "                \n",
    "    #             # Create DataFrame from ticks\n",
    "    #             df = pd.DataFrame(list(ticks))\n",
    "    #             df['tt'] = pd.to_datetime(df['tt'])\n",
    "    #             df.set_index('tt', inplace=True)\n",
    "                \n",
    "    #             #self.logger.info(f\"Processing ticks for token {token}. Tick count: {len(df)}\")\n",
    "\n",
    "    #             # Iterate over each timeframe for OHLC resampling\n",
    "    #             for timeframe in self.tick_collector.VALID_TIMEFRAMES:\n",
    "    #                 if self.tick_collector.resampling_enabled[token].get(timeframe, False):\n",
    "    #                     #self.logger.info(f\"Resampling for token {token} at timeframe {timeframe}\")\n",
    "\n",
    "    #                     resampled = df['ltp'].resample(timeframe).ohlc()\n",
    "                        \n",
    "    #                     # Only update if we have valid resampled data\n",
    "    #                     if not resampled.empty:\n",
    "    #                         # Convert resampled data to dict and store in the resampled_buffers\n",
    "    #                         resampled_records = resampled.reset_index().to_dict('records')\n",
    "    #                         self.tick_collector.resampled_buffers[token][timeframe] = deque(\n",
    "    #                             resampled_records,\n",
    "    #                             maxlen=self.tick_collector.RING_BUFFER_RESAMPLE_SIZE\n",
    "    #                         )\n",
    "    #                         #self.logger.info(f\"Updated resampled buffer for token {token} at timeframe {timeframe}. Resampled count: {len(resampled_records)}\")\n",
    "    #                     else:\n",
    "    #                         self.logger.info(f\"No resampled data for token {token} at timeframe {timeframe}\")\n",
    "    #                 else:\n",
    "    #                     self.logger.info(f\"Resampling not enabled for {token} at {timeframe}\")\n",
    "    async def ohlc_resampling(self):\n",
    "        async with self.tick_collector.processing_lock:\n",
    "            current_time = datetime.now()\n",
    "            for token, ticks in self.tick_collector.ring_buffers.items():\n",
    "                last_tick_time = self.tick_collector.last_tick_time.get(token)\n",
    "                \n",
    "                if last_tick_time is None:\n",
    "                    self.logger.info(f\"No last tick time available for {token}\")\n",
    "                    continue\n",
    "                \n",
    "                time_since_last_tick = current_time - last_tick_time\n",
    "                \n",
    "                if time_since_last_tick > self.IDLE_THRESHOLD:\n",
    "                    self.logger.info(f\"Token {token} idle for {time_since_last_tick}. Will process on next tick.\")\n",
    "                    continue\n",
    "                \n",
    "                if not ticks:\n",
    "                    self.logger.info(f\"No ticks available for {token}\")\n",
    "                    continue\n",
    "                \n",
    "                df = pd.DataFrame(list(ticks))\n",
    "                df['tt'] = pd.to_datetime(df['tt'])\n",
    "                df.set_index('tt', inplace=True)\n",
    "                \n",
    "                for timeframe in self.tick_collector.VALID_TIMEFRAMES:\n",
    "                    if self.tick_collector.resampling_enabled[token].get(timeframe, False):\n",
    "                        last_processed = self.last_processed_time.get((token, timeframe))\n",
    "                        \n",
    "                        if last_processed is None or last_tick_time > last_processed:\n",
    "                            resampled = df['ltp'].resample(timeframe).ohlc().dropna()\n",
    "                            \n",
    "                            if not resampled.empty:\n",
    "                                # Merge with existing data without filling gaps\n",
    "                                existing_data = self.tick_collector.resampled_buffers[token].get(timeframe, deque())\n",
    "                                existing_df = pd.DataFrame(list(existing_data)).set_index('tt') if existing_data else pd.DataFrame()\n",
    "                                \n",
    "                                if not existing_df.empty:\n",
    "                                    # Remove any overlapping data\n",
    "                                    existing_df = existing_df[existing_df.index < resampled.index[0]]\n",
    "                                \n",
    "                                # Concatenate existing data with new data\n",
    "                                combined_df = pd.concat([existing_df, resampled])\n",
    "                                \n",
    "                                # Convert back to records and update the buffer\n",
    "                                resampled_records = combined_df.reset_index().to_dict('records')\n",
    "                                self.tick_collector.resampled_buffers[token][timeframe] = deque(\n",
    "                                    resampled_records,\n",
    "                                    maxlen=self.tick_collector.RING_BUFFER_RESAMPLE_SIZE\n",
    "                                )\n",
    "                                \n",
    "                                self.last_processed_time[(token, timeframe)] = current_time\n",
    "                                self.logger.info(f\"Updated resampled buffer for {token} at {timeframe}. Resampled count: {len(resampled_records)}\")\n",
    "                            else:\n",
    "                                self.logger.info(f\"No resampled data for {token} at {timeframe}\")\n",
    "                        else:\n",
    "                            self.logger.info(f\"No new data for {token} at {timeframe} since last processing.\")\n",
    "                            \n",
    "    async def process_data(self):\n",
    "        #self.logger.info(\"DataProcessor: process_data method started\")\n",
    "        while True:\n",
    "            #self.logger.info(\"DataProcessor: Starting OHLC resampling process...\")\n",
    "            await self.ohlc_resampling()\n",
    "            await asyncio.sleep(1)  # Adjust the sleep time as needed\n",
    "\n",
    "    def get_resampled_buffer_contents(self, token=None, timeframe=None):\n",
    "    \n",
    "        if token is None and timeframe is None:\n",
    "            return {t: {tf: list(b) for tf, b in buffers.items()} \n",
    "                    for t, buffers in self.tick_collector.resampled_buffers.items()}\n",
    "        elif token is not None and timeframe is None:\n",
    "            return {tf: list(b) for tf, b in self.tick_collector.resampled_buffers.get(token, {}).items()}\n",
    "        elif token is not None and timeframe is not None:\n",
    "            return list(self.tick_collector.resampled_buffers.get(token, {}).get(timeframe, deque()))\n",
    "        else:  # token is None and timeframe is not None\n",
    "            return {t: list(buffers.get(timeframe, deque())) \n",
    "                    for t, buffers in self.tick_collector.resampled_buffers.items()}\n",
    "\n",
    "    async def run(self):\n",
    "        await asyncio.gather(\n",
    "            self.process_data()            \n",
    "        )\n",
    "        \n",
    "import nest_asyncio\n",
    "# Global variable to store the DataProcessor instance\n",
    "global_data_processor = None\n",
    "\n",
    "async def main():\n",
    "    global global_data_processor\n",
    "    collector = TickCollector()\n",
    "    processor = DataProcessor(collector)\n",
    "    global_data_processor = processor\n",
    "    \n",
    "    await asyncio.gather(collector.run(), processor.run())\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.set_debug(True)\n",
    "if loop.is_running():\n",
    "    nest_asyncio.apply()\n",
    "asyncio.create_task(main())\n",
    "if not loop.is_running():\n",
    "    try:\n",
    "        loop.run_forever()\n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Received exit signal. Cleaning up...\")\n",
    "    finally:\n",
    "        loop.close()\n",
    "        logger.info(\"Event loop closed. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to run this cell after the main() function has started\n",
    "\n",
    "# Function to get resampled buffer contents\n",
    "def get_buffer_contents(token=None, timeframe=None):\n",
    "    global global_data_processor\n",
    "    if global_data_processor is None:\n",
    "        return \"DataProcessor not initialized yet. Please wait a moment and try again.\"\n",
    "    return global_data_processor.get_resampled_buffer_contents(token, timeframe)\n",
    "\n",
    "# Examples of usage:\n",
    "\n",
    "# Get all resampled buffer contents\n",
    "all_contents = get_buffer_contents()\n",
    "print(\"All contents:\")\n",
    "for token, timeframes in all_contents.items():\n",
    "    print(f\"Token {token}:\")\n",
    "    for tf, data in timeframes.items():\n",
    "        print(f\"  Timeframe {tf}: {len(data)} entries\")\n",
    "        if data:\n",
    "            print(f\"    complete  entry: {data}\")\n",
    "\n",
    "# Get contents for a specific token (e.g., '432294')\n",
    "token_contents = get_buffer_contents(token='432294')\n",
    "print(\"\\nContents for token 432294:\")\n",
    "for tf, data in token_contents.items():\n",
    "    print(f\"  Timeframe {tf}: {len(data)} entries\")\n",
    "    if data:\n",
    "        print(f\"    Latest entry: {data[-1]}\")\n",
    "\n",
    "# Get contents for a specific token and timeframe\n",
    "specific_contents = get_buffer_contents(token='432294', timeframe='1min')\n",
    "print(\"\\nContents for token 432294, 1min timeframe:\")\n",
    "print(f\"  {len(specific_contents)} entries\")\n",
    "if specific_contents:\n",
    "    print(f\"    Latest entry: {specific_contents[-1]}\")\n",
    "\n",
    "# Get contents for a specific timeframe across all tokens\n",
    "timeframe_contents = get_buffer_contents(timeframe='5min')\n",
    "print(\"\\nContents for 5min timeframe:\")\n",
    "for token, data in timeframe_contents.items():\n",
    "    print(f\"  Token {token}: {len(data)} entries\")\n",
    "    if data:\n",
    "        print(f\"    Latest entry: {data[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
